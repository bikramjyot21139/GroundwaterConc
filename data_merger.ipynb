{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBWVL9H0AFh8",
        "outputId": "37cca4ae-55d8-459b-9164-f956634cd61e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.9.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.25.2)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tabula\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your PDF file\n",
        "pdf_file_path ='/content/dfs.pdf'\n",
        "\n",
        "# Read PDF tables into a list of DataFrames\n",
        "pdf_tables = tabula.read_pdf(pdf_file_path, pages='all')\n",
        "\n",
        "# Export each DataFrame to CSV\n",
        "for i, df in enumerate(pdf_tables):\n",
        "    df.to_csv(f\"table_{i+1}.csv\", index=False)\n",
        "\n",
        "print(\"Tables extracted and saved as CSV files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyqGYh1vAMuW",
        "outputId": "d0af071c-26f1-43da-edf7-a1c8d94cb1c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables extracted and saved as CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "pdf_file_path ='/content/dfs.pdf'\n",
        "\n",
        "# Read PDF tables into a list of DataFrames\n",
        "pdf_tables = tabula.read_pdf(pdf_file_path, pages='all')\n",
        "\n",
        "# Export each DataFrame to CSV\n",
        "for i, df in enumerate(pdf_tables):\n",
        "    df.to_csv(f\"table_{i+1}.csv\", index=False)\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through each CSV file and read it into a DataFrame\n",
        "for i in range(1, 41):\n",
        "    df = pd.read_csv(f\"table_{i}.csv\")\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into one\n",
        "merged_table = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Export the merged DataFrame to CSV\n",
        "merged_table.to_csv(\"merged_table.csv\", index=False)\n",
        "\n",
        "print(\"Tables merged and saved as 'merged_table.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXaihqmbDXTw",
        "outputId": "74bc5331-f121-4f11-e057-a036bd1fd7f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables merged and saved as 'merged_table.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through each CSV file and read it into a DataFrame\n",
        "for i in range(1, 41):\n",
        "    # Read CSV into DataFrame\n",
        "    df = pd.read_csv(f\"table_{i}.csv\")\n",
        "\n",
        "    # Remove headers after the first iteration\n",
        "    if i != 1:\n",
        "        df = df.iloc[5:]  # Skip the first row (header)\n",
        "\n",
        "    # Append DataFrame to the list\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into one\n",
        "merged_table = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Export the merged DataFrame to CSV\n",
        "merged_table.to_csv(\"merged_table.csv\", index=False)\n",
        "\n",
        "print(\"Tables merged and saved as 'merged_table.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Wge7RGG9Dm",
        "outputId": "d76abebc-30ab-4619-9a75-1f45316fa96d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables merged and saved as 'merged_table.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# dfs = []\n",
        "\n",
        "# # Loop through each CSV file and read it into a DataFrame\n",
        "# for i in range(1, 41):\n",
        "#     # Read CSV into DataFrame\n",
        "#     df = pd.read_csv(f\"table_{i}.csv\")\n",
        "\n",
        "#     # Remove headers after the first iteration\n",
        "#     if i != 1:\n",
        "#         df = df.iloc[1:]  # Skip the first row (header)\n",
        "\n",
        "#     # Append DataFrame to the list\n",
        "#     dfs.append(df)\n",
        "\n",
        "# # Concatenate all DataFrames into one\n",
        "# merged_table = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# # Keep only the \"gini 2010-2011\" and \"state/districts\" columns\n",
        "# columns_to_keep = [\"state/districts\", \"gini, 2010-2011\"]\n",
        "\n",
        "# # Filter the DataFrame to retain only the specified columns\n",
        "# merged_table = merged_table[[\"state/districts\", \"gini, 2010-2011\"]]\n",
        "\n",
        "# # Drop rows with missing values (NaN)\n",
        "# merged_table = merged_table.dropna()\n",
        "\n",
        "# # Export the merged DataFrame to CSV\n",
        "# merged_table.to_csv(\"merged_table.csv\", index=False)\n",
        "\n",
        "# print(\"Tables merged, missing values dropped, and saved as 'merged_table.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "cXgOyuUvO6hf",
        "outputId": "0efda17c-8cd9-4806-887f-6bbfbe84a876"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['state/districts', 'gini, 2010-2011'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ff5e2c27a130>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Filter the DataFrame to retain only the specified columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmerged_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Drop rows with missing values (NaN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['state/districts', 'gini, 2010-2011'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/sdp1.csv')\n",
        "\n",
        "# Function to search for SDP data\n",
        "def search_sdp(year, state):\n",
        "    # Filter the DataFrame based on the year and state\n",
        "    filtered_df = df[(df['YEAR'][::3] == year) & (df['STATE'] == state)]\n",
        "\n",
        "    # Check if data is found\n",
        "    if not filtered_df.empty:\n",
        "        # Retrieve the SDP data\n",
        "        sdp_data = filtered_df['STATE'].iloc[0]\n",
        "        return sdp_data\n",
        "    else:\n",
        "        return \"SDP data not found for the specified year and state.\"\n",
        "\n",
        "# Example usage\n",
        "# year = '1980-81'\n",
        "# state = 'ANDHRA PRADESH'\n",
        "# sdp_data = search_sdp(year, state)\n",
        "# print(\"SDP data for\", state, \"in the year\", year, \"is:\", sdp_data)\n",
        "df.dropna(inplace=True)\n",
        "new_column_names = {\n",
        "    'Base Year : 1980-81': 'YEAR',\n",
        "    'ANDHRA PRADESH': 'ANDHRA PRADESH',\n",
        "    'ARUNACHAL PRADESH': 'ARUNACHAL PRADESH',\n",
        "    'ASSAM': 'ASSAM',\n",
        "    'BIHAR': 'BIHAR',\n",
        "    'GOA': 'GOA',\n",
        "    'GUJARAT': 'GUJARAT',\n",
        "    'HARYANA': 'HARYANA',\n",
        "    'HIMACHAL PRADESH': 'HIMACHAL PRADESH',\n",
        "    'JAMMU & KASHMIR': 'JAMMU & KASHMIR',\n",
        "    'KARNATAKA': 'KARNATAKA',\n",
        "    'KERALA': 'KERALA',\n",
        "    'MADHYA PRADESH': 'MADHYA PRADESH',\n",
        "    'MAHARASHTRA': 'MAHARASHTRA',\n",
        "    'MANIPUR': 'MANIPUR',\n",
        "    'MEGHALAYA': 'MEGHALAYA',\n",
        "    'NAGALAND': 'NAGALAND',\n",
        "    'ORISSA': 'ORISSA',\n",
        "    'PUNJAB': 'PUNJAB',\n",
        "    'RAJASTHAN': 'RAJASTHAN',\n",
        "    'SIKKIM': 'SIKKIM',\n",
        "    'TAMIL NADU': 'TAMIL NADU',\n",
        "    'TRIPURA': 'TRIPURA',\n",
        "    'UTTAR PRADESH': 'UTTAR PRADESH',\n",
        "    'WEST BENGAL': 'WEST BENGAL',\n",
        "    'ANDAMAN & NICOBAR ISLANDS': 'ANDAMAN & NICOBAR ISLANDS',\n",
        "    'DELHI': 'DELHI',\n",
        "    'PUDUCHERRY': 'PUDUCHERRY'\n",
        "}\n",
        "\n",
        "# Rename the columns\n",
        "df.rename(columns=new_column_names, inplace=True)\n",
        "\n",
        "# Verify the column names\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iN1qGR3Vf1v",
        "outputId": "be65bdac-5041-4c0e-d898-afc901911913"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['NET STATE DOMESTIC PRODUCT AT FACTOR COST - STATE-WISE(At Constant Prices)',\n",
            "       'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5',\n",
            "       'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10',\n",
            "       'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14',\n",
            "       'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
            "       'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22',\n",
            "       'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26',\n",
            "       'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30',\n",
            "       'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}